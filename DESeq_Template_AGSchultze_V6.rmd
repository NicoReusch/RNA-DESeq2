---
title: "DESeq2 RNA-seq Analysis Template"
author: "Stefanie Herresthal, Nico Reusch, Jonas Schulte-Schrepping"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document: 
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide
---

# Done: 

* sample annotation in table output (Nico) DONE
* add Gene annotation to DE_object (Nico) DONE
* print gene expression for multiple matching Ensembl IDs (Nico) DONE
* Same style for PCAs (Nico) DONE
* merge fastqc and sample table (Steffi) DONE
* QC plots: Alignment Statistik etc (Steffi) DONE

# TO DO: 

* Zentraler Speicherort fÃ¼r Annotationsfiles

* Multiplot PCA (Jonas)
* LFC Shrinkage always appropriate? Which shrinkage function? (all)
* Heatmap function: Issue of duplicate gene symbols for visualization (Jonas)
* cumulative variance plot for HC gene selection (Jonas)
* add more annotation (e.g. gene description) to normalized count table  (Jonas)
* DE-gene downstream figures: MA-plot, Volcano, Gene set enrichment, ... (Jonas)
* analysis of union of DE genes: HC, CompareCluster, ... (Steffi)
* Heatmap of GO genes (filtered for DE genes)
* Custom GO enrichment visualization --> in ggplot2 (Steffi)
* Add sample information to count table (Nico)

* Interactive chossing of QC cutoff
* check for unnecessary packages (e.g. r2excel)
* Colour code: Input Konditionen, Output: Automatisierte Farbverteilung (Steffi)
* interactive visualization of tables


# Project information

## General specifications of the project: 

* General scienfitic question: 

* Samples: 
* Conditions:
* Species:
* Cell type(s):

* Seq-Tracker: 

* RNA-isolation: 
* QC Check: 
* Library-Production: 
* QC Check: 
* Sequencing method to be used:
* Sequencing run: 
* Alignment: 
* QC: 
* Data Analysis: 

* Project directories on Illumina: 
* Project directory on blades: 

## Workflow Summary
*Space for notes concerning the global workflow and quality checks.*

# Folder requirements 

## Project directory
Specify the project directory here: 
```{r, warning=F}
dir <- "E:/sciebo/DESeq2_pipeline"

# creating directories if not already existing:
dir.create(file.path(dir, "Analysis"), recursive = T)
dir.create(file.path(dir, "Analysis", "Tables"), recursive = T)
dir.create(file.path(dir, "Analysis", "Plots"), recursive = T)
```

## Content of directory
The project directory needs to contain a folder *Data* containing: 

* The output folder of the bulk RNAseq Kallisto pipeline including the folders *kallisto* and *qc* 
* The kallisto files should be in: *Data/output/kallisto/kallisto/*
* The qc files should be in: 
      *Data/output/kallisto/mutiqc/multiqc_data/multiqc_kallisto.txt* and 
      *Data/output/qc/multiqc/multiqc_data/multiqc_fastqc.txt*. 

* sample table:  *Data/sample_table.txt*. 

This table should contain *at least* the following columns: 
    + Sample Identifier (e.g. 3609): "ID"
    + Sample Name (e.g. wt_8mo_5870): "sample_name"
    + Condition (e.g. wt_8mo): "condition"   --> merged sample information that is used for DE calling 
    + Optional additional information: gender, age, date of experiment, ... 

* gene annotation. Specify the filename here: 

```{r}
annotation_filename <- "ID2SYMBOL_gencode_vM13_transcript.txt"
```

# R requirements
## Install and load packages

All packages to load and install

```{r load packages, echo=FALSE, results='hide',message=FALSE,warning=FALSE}
# CRAN packages
list.of.packages <- c("hwriter",
                      "RColorBrewer",
                      "tidyverse",
                      "reshape2",
                      "dplyr",
                      "stringr",
                      "pheatmap",
                      "colourlovers",
                      "VennDiagram", 
                      "ggbeeswarm",
                      "scales",
                      "magrittr", 
                      "tidyr",
                      "bit", 
                      "data.table",
                      "RSQLite",
                      "Rcpp", 
                      "devtools",
                      "matrixStats", 
                      "xlsx", 
                      "gridBase", 
                      "survival", 
                      "rlang", 
                      "MASS", 
                      "ggforce",
                      "tibble",
                      "stringi",
                      "gtools",
                      "ggrepel",
                      "Hmisc", 
                      "gplots",
                      "ggplot2",
                      "factoextra")

new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]

if(length(new.packages)>0) install.packages(new.packages)

# BioconductoR packages
list.of.bioc.packages<- c("rhdf5",
                          "DESeq2",
                          "IHW",
                          "clusterProfiler",
                          "GSEABase",
                          "AnnotationDbi",
                          "sva",
                          "tximport",
                          "limma",
                          "geneplotter",
                          "genefilter",
                          "org.Mm.eg.db",
                          "org.Hs.eg.db",
                          "biomaRt", 
                          "ReactomePA", 
                          "grid",
                          "pcaGoPromoter",
                          "pcaGoPromoter.Hs.hg19",
                          "pcaGoPromoter.Mm.mm9", 
                          "limma", 
                          "DOSE",
                          "vsn",
                          "ComplexHeatmap")

new.packages.bioc <- list.of.bioc.packages[!(list.of.bioc.packages %in% installed.packages()[,"Package"])]

source("https://bioconductor.org/biocLite.R")
if(length(new.packages.bioc)>0) biocLite(new.packages.bioc,suppressUpdates=TRUE)

lapply(c(list.of.packages,list.of.bioc.packages), require, character.only = TRUE)
```

## Define analysis functions

```{r global functions, hide = T, cache = T}
# Function to perform variance stabilizing transformation (rlog for less than 30 samples, vst for more than 30 samples)
varStab<- function(blind_param=T){
  if(length(samples_to_keep)<30){
    rld<-rlog(dds, blind=blind_param)
  }
  else{
    vst <- vst(dds, blind = blind_param)
  }
}

# Function for plotting multiple plots in grid
multiplot<-function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}


# Specify structure of DESeq2_analysis_object
setClass(Class = "DESeq2_analysis_object",
         slots = c(parameters="list", results="data.frame", DE_genes="list", Number_DE_genes="list"))


# Wrapper Function to perform DESeq2 differential testing
DEAnalysis <- function(alpha_option=0.05, 
                         lfc_Threshold=0,
                         condition=condition,
                         multiple_testing="IHW"){
  DE_objects <- list()
  
    #creat DE_object
    DE_object <- new(Class = "DESeq2_analysis_object")
    
    # Define parameters
    for (i in 1:nrow(comparison_table)){
      list_DE_genes <- list()
      
      # IHW
      if (multiple_testing=="IHW") {
        res_deseq_lfc <- results(dds,
                                 contrast = c(condition,
                                              paste(comparison_table$comparison[i]),
                                              paste(comparison_table$control[i])),
                                 lfcThreshold = lfc_Threshold,
                                 alpha = alpha_option,
                                 filterFun = ihw,
                                 altHypothesis = "greaterAbs")
                
        # Do we necessarily always want to perform the fold change shrinkage? Which shrinkage function do we want to use?
        res_deseq_lfc <- lfcShrink(dds, 
                                   contrast = c(condition,
                                                paste(comparison_table$comparison[i]),
                                                paste(comparison_table$control[i])),
                                   res=res_deseq_lfc)
        res_deseq_lfc <- as.data.frame(res_deseq_lfc)
        
        # Now we delog-transform the shrunken fold changes?
        res_deseq_lfc$FC <- logratio2foldchange(res_deseq_lfc$log2FoldChange,base=2)
        
        res_deseq_lfc$significance <- ifelse(res_deseq_lfc$padj <=alpha_option&
                                             !is.na(res_deseq_lfc$padj)&
                                             abs(res_deseq_lfc$log2FoldChange)>lfc_Threshold, 
                                           "T", 
                                           "F")
        
        res_deseq_lfc$regulation <-ifelse(res_deseq_lfc$log2FoldChange>lfc_Threshold,"up","down")
      }
      
      # Independent Filtering
      else {
        res_deseq_lfc <- results(dds,
                                 contrast = c(condition,
                                          paste(comparison_table$comparison[i]),
                                          paste(comparison_table$control[i])),
                                 lfcThreshold = lfc_Threshold,
                                 alpha = alpha_option,
                                 independentFiltering = T,
                                 altHypothesis = "greaterAbs",
                                 pAdjustMethod=multiple_testing)
        
        res_deseq_lfc <- lfcShrink(dds, 
                                   contrast = c(condition,
                                                paste(comparison_table$comparison[i]), 
                                                paste(comparison_table$control[i])),
                                   res=res_deseq_lfc)
        
        res_deseq_lfc <- as.data.frame(res_deseq_lfc)
        
        res_deseq_lfc$FC <- logratio2foldchange(res_deseq_lfc$log2FoldChange,base=2)
        
        res_deseq_lfc$significance<-ifelse(res_deseq_lfc$padj<=alpha_option&                  
                                            !is.na(res_deseq_lfc$padj)&
                                            abs(res_deseq_lfc$log2FoldChange)>lfc_Threshold,
                                           "T", 
                                           "F")
        
        res_deseq_lfc$regulation <-ifelse(res_deseq_lfc$log2FoldChange>lfc_Threshold,"up","down")
      } 
      # print parameters
      parameters <-list(multiple_testing, 
                        alpha_option, 
                        lfc_Threshold, 
                        paste(comparison_table$comparison[i]), 
                        paste(comparison_table$control[i]))
      names(parameters)<-c("multiple_testing",
                           "p_value_threshold",
                           "lfc_threshold",
                           "comparison",
                           "control")
      DE_object@parameters <- parameters
      
      # add gene annotation to results table
      res_deseq_lfc$ENS_ID <- row.names(res_deseq_lfc) # ensembl-IDs as row names
      res_deseq_lfc <- merge(res_deseq_lfc, 
                             gene_annotation[!duplicated(gene_annotation$GENEID),c("GENEID", 
                                                                                   "SYMBOL", 
                                                                                   "GENETYPE")], 
                             by.y = "GENEID", 
                             by.x = "ENS_ID", 
                             all.x = F) 

      res_deseq_lfc$ENS_ID<-NULL
      res_deseq_lfc$comparison<-paste(comparison_table$comparison[i],"VS",comparison_table$control[i],
                                      sep="_")
      res_deseq_lfc<-res_deseq_lfc[c(13,11,12,1:10)] 
      
      DE_object@results <- res_deseq_lfc
      
      # print DE genes 
      list_DE_genes <- list(rownames(res_deseq_lfc[!is.na(res_deseq_lfc$padj)&
                                                    res_deseq_lfc$padj<alpha_option&                                                                           res_deseq_lfc$log2FoldChange>lfc_Threshold,]),
                            rownames(res_deseq_lfc[!is.na(res_deseq_lfc$padj)&
                                                    res_deseq_lfc$padj<alpha_option&
                                                    res_deseq_lfc$log2FoldChange<(-lfc_Threshold),]))
      names(list_DE_genes) = c(paste("up-regulated genes"), 
                               paste("down-regulated genes"))
      DE_object@DE_genes <- list_DE_genes
      up<-length(list_DE_genes[[1]])
      down<-length(list_DE_genes[[2]])
      number_of_genes<-list(up,down)
      names(number_of_genes)<-c("up-regulated genes","down-regulated genes")
    DE_object@Number_DE_genes <- number_of_genes
    
    DE_objects[[paste(comparison_table$comparison[i], "VS", comparison_table$control[i], sep="_")]] <- assign(paste(comparison_table$comparison[i]), DE_object)}
  return(DE_objects)
}


# Function to remove potential batch effects using limma
removeBatchEffect_function <- function(x=rld_df,
                                       batch = sample_table[c("Mouse_ID")],
                                       batch_2=NULL,
                                       model = model.matrix(~sample_table$merged)){
  if(is.numeric(batch[,1])==T){
    as.data.frame(removeBatchEffect(x=as.matrix(x),
                      covariates = batch,
                      design = model))}
  else{
    if(is.null(batch_2)){
      as.data.frame(removeBatchEffect(x=x,
                      batch = batch[,1],
                      design = model))
    }
    else{
      as.data.frame(removeBatchEffect(x=x,
                      batch = batch,
                      batch2 = batch_2,
                      design = model))
    }
  }
}

# Function to plot PCA after limma batch removal
Limma_batch <- function(model=model.matrix(~sample_table$condition),
                        batch=sample_table$Sex,
                        batch_2=NULL,
                        shape_opt="Sex",
                        ntop=500, PC_1=1, PC_2=2,
                        color_obj="Treatment",
                        anno_colour=anno_merged,
                        continuous=F,
                        colour_gradient=bluered(100),
                        point_size=3,
                        title="PcA of batch_corrected counts"){
  removedbatch_rld <- removeBatchEffect_function(x=as.data.frame(assay(dds_vst)),
                                                 batch =batch,
                                                 batch_2=batch_2,
                                                 model =model.matrix(~sample_table$condition))
  dds_vst_f_df<-as.matrix(assay(dds_vst))
  if(ntop=="all"){
    pca <- prcomp(t(removedbatch_rld)) 
  }
  else{
    # select the ntop genes by variance
    rv <- rowVars(dds_vst_f_df)
    
    select <- order(rv, decreasing=TRUE)[seq_len(min(ntop, length(rv)))]
    
    pca <- prcomp(t(removedbatch_rld[select,]))
  }
  
  
  percentVar <- pca$sdev^2 / sum( pca$sdev^2 )
  
  color_title<-paste0(color_obj)
  
  color_obj.df <- as.data.frame(color_obj)
  group <- color_obj
  pcaData <- data.frame(PC1=pca$x[,PC_1], PC2=pca$x[,PC_2], group=group, color_obj.df, name=colnames(dds))
  colnames(pcaData)[1] <- paste("PC_1")
  colnames(pcaData)[2] <- paste("PC_2")
  attr(pcaData, "percentVar") <- percentVar[c(PC_1,PC_2)]
  pcaData$condition <- pcaData[,4]
  
  # transform variance to percent
  percentVar <- round(100 * attr(pcaData, "percentVar"))
  
  #plot PCA
  if(continuous ==F){
    if(is.null(anno_colour)){
      
      if(shape_opt=="NULL"){
        pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=condition)) +
          geom_point(size =point_size) +
          scale_color_discrete(name=color_title)+
          xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
          ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
          coord_fixed()+
          theme_classic()+        
            theme(aspect.ratio = 1)
      }
      else{
        if (length(levels(sample_table[[paste0(shape_opt)]]))<6){
          pcaData["new"]<- as.character(sample_table[[paste0(shape_opt)]])
          legend_title <- paste0(shape_opt)
          pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=condition, shape=new)) +
            geom_point(size =point_size) +
            scale_color_discrete(name=color_title)+
            scale_shape(name=legend_title)+
            xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
            ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
            coord_fixed()+
            theme_classic()+           
            theme(aspect.ratio = 1)
        }
        else{
          pcaData["new"]<- as.character(sample_table[[paste0(shape_opt)]])
          legend_title <- paste0(shape_opt)
          pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=condition, shape=new)) +
            geom_point(size =point_size) +
            scale_color_discrete(name=color_title)+
            scale_shape_manual(values=df$x,name=legend_title)+
            xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
            ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
            coord_fixed()+
 
            theme_classic()+           
            theme(aspect.ratio = 1)
          
        }}
    }
    else{
      if(shape_opt=="NULL"){
        pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=condition)) +
          geom_point(size =point_size) +
          scale_color_manual(values=anno_colour, name=color_title)+
          xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
          ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
          coord_fixed()+
          
          theme_classic()+           
          theme(aspect.ratio = 1)
      }
      else{
        if (length(levels(sample_table[[paste0(shape_opt)]]))<6){
          pcaData["new"]<- as.character(sample_table[[paste0(shape_opt)]])
          legend_title <- paste0(shape_opt)
          pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=condition, shape=new)) +
            geom_point(size =point_size) +
            scale_color_manual(values=anno_colour, name=color_title)+
            scale_shape(name=legend_title)+
            xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
            ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
            coord_fixed()+
 
            theme_classic()+           
            theme(aspect.ratio = 1)
        }
        else{
          pcaData["new"]<- as.character(sample_table[[paste0(shape_opt)]])
          legend_title <- paste0(shape_opt)
          pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=condition, shape=new)) +
            geom_point(size =point_size) +
            scale_color_manual(values=anno_colour, name=color_title)+
            scale_shape_manual(values=df$x,name=legend_title)+
            xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
            ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
            coord_fixed()+
 
            theme_classic()+           
            theme(aspect.ratio = 1)
          
        }}
    }
  }
  if(continuous==T){
    if(shape_opt=="NULL"){
      color_obj<-as.integer(sample_table[[paste0(color_obj)]])
      pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=color_obj)) +
        geom_point(size =point_size) +
        scale_color_gradientn(colours = colour_gradient,name=color_title)+
        xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
        ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
        coord_fixed()+
        
        theme_classic()+           
        theme(aspect.ratio = 1)
    }
    else{
      if (length(levels(sample_table[[paste0(shape_opt)]]))<6){
        color_obj<-as.integer(sample_table[[paste0(color_obj)]])
        pcaData["new"]<- as.character(sample_table[[paste0(shape_opt)]])
        legend_title <- paste0(shape_opt)
        pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=color_obj, shape=new)) +
          geom_point(size =point_size) +
          scale_color_gradientn(colours = colour_gradient,name=color_title)+
          scale_shape(name=legend_title)+
          xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
          ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
          coord_fixed()+
          
          theme_classic()+           
          theme(aspect.ratio = 1)
      }
      else{
        color_obj<-as.integer(sample_table[[paste0(color_obj)]])
        pcaData["new"]<- as.character(sample_table[[paste0(shape_opt)]])
        legend_title <- paste0(shape_opt)
        pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=color_obj, shape=new)) +
          geom_point(size =point_size) +
          scale_color_gradientn(colours = colour_gradient,name=color_title)+
          scale_shape_manual(values=df$x,name=legend_title)+
          xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
          ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
          coord_fixed()+
          
          theme_classic()+           
          theme(aspect.ratio = 1)
        
      }}
  }
  pca_plot+
    ggtitle(title)
}

plot_pca <- function(input=dds_vst,
                        shape_opt="Sex",
                        ntop=500, PC_1=1, PC_2=2,
                        color_obj="Treatment",
                        anno_colour=anno_merged,
                        continuous=F,
                        colour_gradient=bluered(100),
                        point_size=3,
                     title="PCA"){
  
  dds_vst_f_df<-as.matrix(assay(dds_vst))
  if(ntop=="all"){
    pca <- prcomp(t(dds_vst_f_df)) 
  }
  else{
    # select the ntop genes by variance
    rv <- rowVars(dds_vst_f_df)
    
    select <- order(rv, decreasing=TRUE)[seq_len(min(ntop, length(rv)))]
    
    pca <- prcomp(t(dds_vst_f_df[select,]))
  }
  
  
  percentVar <- pca$sdev^2 / sum( pca$sdev^2 )
  
  color_title<-paste0(color_obj)
  
  color_obj.df <- as.data.frame(sample_table[[color_obj]])
  group <- color_obj
  pcaData <- data.frame(PC1=pca$x[,PC_1], PC2=pca$x[,PC_2], group=group, color_obj.df, name=colnames(dds))
  colnames(pcaData)[1] <- paste("PC_1")
  colnames(pcaData)[2] <- paste("PC_2")
  attr(pcaData, "percentVar") <- percentVar[c(PC_1,PC_2)]
  pcaData$condition <- pcaData[,4]
  
  # transform variance to percent
  percentVar <- round(100 * attr(pcaData, "percentVar"))
  
  #plot PCA
  if(continuous ==F){
    if(is.null(anno_colour)){
      
      if(shape_opt=="NULL"){
        pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=condition)) +
          geom_point(size =point_size) +
          scale_color_discrete(name=color_title)+
          xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
          ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
          coord_fixed()+
          theme_classic()+        
            theme(aspect.ratio = 1)
      }
      else{
        if (length(levels(sample_table[[paste0(shape_opt)]]))<6){
          pcaData["new"]<- as.character(sample_table[[paste0(shape_opt)]])
          legend_title <- paste0(shape_opt)
          pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=condition, shape=new)) +
            geom_point(size =point_size) +
            scale_color_discrete(name=color_title)+
            scale_shape(name=legend_title)+
            xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
            ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
            coord_fixed()+
            theme_classic()+           
            theme(aspect.ratio = 1)
        }
        else{
          pcaData["new"]<- as.character(sample_table[[paste0(shape_opt)]])
          legend_title <- paste0(shape_opt)
          pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=condition, shape=new)) +
            geom_point(size =point_size) +
            scale_color_discrete(name=color_title)+
            scale_shape_manual(values=df$x,name=legend_title)+
            xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
            ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
            coord_fixed()+
 
            theme_classic()+           
            theme(aspect.ratio = 1)
          
        }}
    }
    else{
      if(shape_opt=="NULL"){
        pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=condition)) +
          geom_point(size =point_size) +
          scale_color_manual(values=anno_colour, name=color_title)+
          xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
          ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
          coord_fixed()+
          
          theme_classic()+           
          theme(aspect.ratio = 1)
      }
      else{
        if (length(levels(sample_table[[paste0(shape_opt)]]))<6){
          pcaData["new"]<- as.character(sample_table[[paste0(shape_opt)]])
          legend_title <- paste0(shape_opt)
          pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=condition, shape=new)) +
            geom_point(size =point_size) +
            scale_color_manual(values=anno_colour, name=color_title)+
            scale_shape(name=legend_title)+
            xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
            ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
            coord_fixed()+
 
            theme_classic()+           
            theme(aspect.ratio = 1)
        }
        else{
          pcaData["new"]<- as.character(sample_table[[paste0(shape_opt)]])
          legend_title <- paste0(shape_opt)
          pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=condition, shape=new)) +
            geom_point(size =point_size) +
            scale_color_manual(values=anno_colour, name=color_title)+
            scale_shape_manual(values=df$x,name=legend_title)+
            xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
            ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
            coord_fixed()+
 
            theme_classic()+           
            theme(aspect.ratio = 1)
          
        }}
    }
  }
  if(continuous==T){
    if(shape_opt=="NULL"){
      color_obj<-as.integer(sample_table[[paste0(color_obj)]])
      pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=color_obj)) +
        geom_point(size =point_size) +
        scale_color_gradientn(colours = colour_gradient,name=color_title)+
        xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
        ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
        coord_fixed()+
        
        theme_classic()+           
        theme(aspect.ratio = 1)
    }
    else{
      if (length(levels(sample_table[[paste0(shape_opt)]]))<6){
        color_obj<-as.integer(sample_table[[paste0(color_obj)]])
        pcaData["new"]<- as.character(sample_table[[paste0(shape_opt)]])
        legend_title <- paste0(shape_opt)
        pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=color_obj, shape=new)) +
          geom_point(size =point_size) +
          scale_color_gradientn(colours = colour_gradient,name=color_title)+
          scale_shape(name=legend_title)+
          xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
          ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
          coord_fixed()+
          
          theme_classic()+           
          theme(aspect.ratio = 1)
      }
      else{
        color_obj<-as.integer(sample_table[[paste0(color_obj)]])
        pcaData["new"]<- as.character(sample_table[[paste0(shape_opt)]])
        legend_title <- paste0(shape_opt)
        pca_plot <- ggplot(pcaData, aes(x = PC_1, y = PC_2,colour=color_obj, shape=new)) +
          geom_point(size =point_size) +
          scale_color_gradientn(colours = colour_gradient,name=color_title)+
          scale_shape_manual(values=df$x,name=legend_title)+
          xlab(paste0("PC ",PC_1, ": ", percentVar[1], "% variance")) +
          ylab(paste0("PC ",PC_2,": ", percentVar[2], "% variance")) +
          coord_fixed()+
          
          theme_classic()+           
          theme(aspect.ratio = 1)
        
      }}
  }
  pca_plot+
    ggtitle(title)
}


# Function to create breaks and colour vectors scaled to 0 (middle) and a specified value (upper and lower bound)
scaleColors <- function(data = heatmap_scale, # data to use
                        maxvalue = NULL # value at which the color is fully red / blue
                        ){
  if(is.null(maxvalue)){
    maxvalue <- floor(min(abs(min(data)), max(data)))
  }
  
if(max(data) > abs(min(data))){
  myBreaks <- c(floor(-max(data)), seq(-maxvalue, maxvalue, 0.2),  ceiling(max(data)))
  paletteLength <- length(myBreaks)
  myColor <- colorRampPalette(c("blue", "white", "red"))(paletteLength)
} else {
  myBreaks <- c(floor(min(data)), seq(-maxvalue, maxvalue, 0.2),  ceiling(abs(min(data))))
  paletteLength <- length(myBreaks)
  myColor <- colorRampPalette(c("blue", "white", "red"))(paletteLength)
}
  return(list(breaks = myBreaks, color = myColor))
}


# This function plots the batch-corrected counts
plot_single_gene <-function(input=norm_anno, gene_symbol="Crybg3", 
                            condition="Genotype_Age", anno_colour=Genotype_Age_col,
                            shape_opt="age") {
  input<-as.data.frame(input)
  if(length(which(input$SYMBOL==gene_symbol))>1){
    print("More than one Gene symbols assigned to this Ensembl ID")
  plots<-list()
  geneCounts_lfc <- as.data.frame(t(input[input[["SYMBOL"]]==gene_symbol,][ , -which(names(input) %in% c("ENS_ID","SYMBOL","GENETYPE"))]))
  for (i in 1:ncol(geneCounts_lfc)) {
    geneCounts_lfc <- as.data.frame(t(input[input[["SYMBOL"]]==gene_symbol,][ , -which(names(input) %in% c("ENS_ID","SYMBOL","GENETYPE"))]))
  geneCounts_lfc$condition <- sample_table[[condition]]
    title<-colnames(geneCounts_lfc)[i]
    colnames(geneCounts_lfc)[i]<-"y"
  if(is.null(anno_colour)==F){
    if (is.null(shape_opt)==T){
      plot<-ggplot(geneCounts_lfc, aes(x = condition, y = y, colour=condition)) +
        scale_y_continuous(expand=c(0.05,0.25)) +  
        scale_color_manual(values=anno_colour)+
        geom_beeswarm(cex = 3, na.rm=T)+
        ylab("Normalized counts")+
        labs(title=paste(gene_symbol, title,sep=": "),colour=condition)+
        theme_classic()+
        theme(plot.title = element_text(hjust=0.5))+
        expand_limits(y=0)+
        stat_boxplot(geom ='errorbar',width=.25)+
        geom_boxplot(width=.5,alpha=0)}
    else{
      geneCounts_lfc$sign <- sample_table[[paste0(shape_opt)]]
      legend_shape<-paste0(shape_opt)
      plot<-ggplot(geneCounts_lfc, aes(x = condition, y = y, colour=condition, shape=sign)) +
        scale_y_continuous(expand=c(0.05,0.25)) +   
        scale_color_manual(values=anno_colour)+
        scale_shape(name=legend_shape)+
        geom_beeswarm(cex = 3, na.rm=T)+
        ylab("Normalized counts")+
        labs(title=paste(gene_symbol, title,sep=": "),colour=condition)+
        theme_classic()+
        theme(plot.title = element_text(hjust=0.5))+
        expand_limits(y=0)+
        stat_boxplot(geom ='errorbar',width=.25)+
        geom_boxplot(width=.5,alpha=0)}}
  else{
    if (is.null(shape_opt)==T){
      plot<-ggplot(geneCounts_lfc, aes(x = condition, y = y, colour=condition)) +
        scale_y_continuous(expand=c(0.05,0.25)) +  
        scale_color_brewer(palette = "Spectral")+
        geom_beeswarm(cex = 3, na.rm=T)+
        ylab("Normalized counts")+
        labs(title=paste(gene_symbol, title,sep=": "),colour=condition)+
        theme_classic()+
        theme(plot.title = element_text(hjust=0.5))+
        expand_limits(y=0)+
        stat_boxplot(geom ='errorbar',width=.25)+
        geom_boxplot(width=.5,alpha=0)}
    else{
      geneCounts_lfc$sign <- sample_table[[paste0(shape_opt)]]
      legend_shape<-paste0(shape_opt)
      plot<-ggplot(geneCounts_lfc, aes(x = condition, y = y, colour=condition, shape=sign)) +
        scale_y_continuous(expand=c(0.05,0.25)) +  
        scale_color_brewer(palette = "Spectral")+
        scale_shape(name=legend_shape)+
        geom_beeswarm(cex = 3, na.rm=T)+
        ylab("Normalized counts")+
        labs(title=paste(gene_symbol, title,sep=": "),colour=condition)+
        theme_classic()+
        theme(plot.title = element_text(hjust=0.5))+
        expand_limits(y=0)+
        stat_boxplot(geom ='errorbar',width=.25)+
        geom_boxplot(width=.5,alpha=0)
    }
  }
  plots[[i]]<-plot
  }
  multiplot(plots)
  }
  else{
  geneCounts_lfc <- as.data.frame(t(input[input[["SYMBOL"]]==gene_symbol,][ , -which(names(input) %in% c("ENS_ID","SYMBOL","GENETYPE"))]))
  
  geneCounts_lfc$condition <- sample_table[[condition]]
  colnames(geneCounts_lfc)<-c("count","condition")
  if(is.null(anno_colour)==F){
    if (is.null(shape_opt)==T){
      ggplot(geneCounts_lfc, aes(x = condition, y = count, colour=condition)) +
        scale_y_continuous(expand=c(0.05,0.25)) +  
        scale_color_manual(values=anno_colour)+
        geom_beeswarm(cex = 3, na.rm=T)+
        ylab("Normalized counts")+
        labs(title=paste0(gene_symbol),colour=condition)+
        theme_classic()+
        theme(plot.title = element_text(hjust=0.5))+
        expand_limits(y=0)+
        stat_boxplot(geom ='errorbar',width=.25)+
        geom_boxplot(width=.5,alpha=0)}
    else{
      geneCounts_lfc$sign <- sample_table[[paste0(shape_opt)]]
      legend_shape<-paste0(shape_opt)
      ggplot(geneCounts_lfc, aes(x = condition, y = count, colour=condition, shape=sign)) +
        scale_y_continuous(expand=c(0.05,0.25)) +   
        scale_color_manual(values=anno_colour)+
        scale_shape(name=legend_shape)+
        geom_beeswarm(cex = 3, na.rm=T)+
        ylab("Normalized counts")+
        labs(title=paste0(gene_symbol),colour=condition)+
        theme_classic()+
        theme(plot.title = element_text(hjust=0.5))+
        expand_limits(y=0)+
        stat_boxplot(geom ='errorbar',width=.25)+
        geom_boxplot(width=.5,alpha=0)}}
  else{
    if (is.null(shape_opt)==T){
      ggplot(geneCounts_lfc, aes(x = condition, y = count, colour=condition)) +
        scale_y_continuous(expand=c(0.05,0.25)) +  
        scale_color_brewer(palette = "Spectral")+
        geom_beeswarm(cex = 3, na.rm=T)+
        ylab("Normalized counts")+
        labs(title=paste0(gene_symbol),colour=condition)+
        theme_classic()+
        theme(plot.title = element_text(hjust=0.5))+
        expand_limits(y=0)+
        stat_boxplot(geom ='errorbar',width=.25)+
        geom_boxplot(width=.5,alpha=0)}
    else{
      geneCounts_lfc$sign <- sample_table[[paste0(shape_opt)]]
      legend_shape<-paste0(shape_opt)
      ggplot(geneCounts_lfc, aes(x = condition, y = count, colour=condition, shape=sign)) +
        scale_y_continuous(expand=c(0.05,0.25)) +  
        scale_color_brewer(palette = "Spectral")+
        scale_shape(name=legend_shape)+
        geom_beeswarm(cex = 3, na.rm=T)+
        ylab("Normalized counts")+
        labs(title=paste0(gene_symbol),colour=condition)+
        theme_classic()+
        theme(plot.title = element_text(hjust=0.5))+
        expand_limits(y=0)+
        stat_boxplot(geom ='errorbar',width=.25)+
        geom_boxplot(width=.5,alpha=0)
    }
  }
  }}

```

# User customizations 
## Colour scheme
Define you colour schemes according to your data set and your variables

```{r}
Genotype <- c("#90D95E", "#86BE9E")
names(Genotype) <- c("wt", "tg") 
Age = c("#FFEDA0", "#FEB24C", "#F03B20")
names(Age) <- c("4mo", "8mo", "12mo")
Sex <- c("##66C3D0", "#008DD2")
names(Sex) <- c("f", "m")
Genotype_Age_col <- c(brewer.pal(3, "Blues"), brewer.pal(3, "Oranges"))
names(Genotype_Age_col) <- c("wt_4mo", "wt_8mo", "wt_12mo", "tg_4mo", "tg_8mo", "tg_12mo")
```


# Data Import

## Load gene annotation
Transcript to Ensembl-ID-Mapping and Gene Annotation. 
Exact annotation file name has to be specified here. 
Annotation file has to consist of four columns: Gene ENSEMBL ID, Transcript ID, Gene Symbol, Gene Type.

```{r gene annotation import}
gene_annotation <- read.delim(file.path(dir, "Data", annotation_filename), 
                         header = F , 
                         col.names = c("GENEID", "TXNAME", "SYMBOL", "GENETYPE"))
```

## Load sample table

Here, we read a table containing all available metainformation of the samples. 
```{r sample table import}
sample_table <- read.delim(file.path(dir, "Data", "sample_table.txt"))
sample_table
```

# Quality check

## Fastq QC
Reads FastQC MultiQC output and merges the information with the sample_table
```{r MultiQC import}
fastq_qc <- read.delim(file.path(dir, "Data", "output", "qc", "multiqc", "multiqc_data", "multiqc_fastqc.txt"), stringsAsFactors = F)
fastq_qc$Sample <- unlist(lapply(strsplit(fastq_qc$Sample, split = "_"), `[[`, 2)) # changes sample identifiers
#fastq_qc <- fastq_qc[, c("Sample", "Total.Sequences", "Sequences.flagged.as.poor.quality", "X.GC", "total_deduplicated_percentage", "avg_sequence_length", "basic_statistics", "per_base_sequence_quality", "per_tile_sequence_quality", "per_sequence_quality_scores", "per_base_sequence_content", "per_sequence_gc_content","per_base_n_content", "sequence_length_distribution", "sequence_duplication_levels", "overrepresented_sequences", "adapter_content")]

# Merge QC and sample files (include only the samples that are also in the sample table)
sample_table <- merge(sample_table, fastq_qc, by.y = "Sample", by.x = "ID")
rownames(sample_table) <- sample_table$ID
```

## Kallisto QC
Reads Kallisto MultiQC output and merges the information with the sample_table
```{r Kallisto QC import}
kallisto_qc <- read.delim(file.path(dir, "Data", "output", "kallisto", "multiqc", "multiqc_data", "multiqc_kallisto.txt"), stringsAsFactors = F)

# change sample column 
kallisto_qc$Sample <- do.call(rbind, strsplit(kallisto_qc$Sample, split = "\\_"))[,1]

# Merge QC and sample files 
sample_table <- merge(sample_table, kallisto_qc, by.y = "Sample", by.x = "ID")
rownames(sample_table) <- sample_table$ID
```

## QC Plots

### HC of FastQC overall quality

```{r}
QCHeatmap <- function(){
  
  mat <- sample_table
  rownames(mat) <- paste(mat$ID, mat$sample_name, sep = "_")
  mat$sample_name <- as.character.factor(mat$sample_name)
  mat$Sex <- as.character.factor(mat$Sex)
  
  
  
  ht <-  Heatmap(mat[,names(mat) %in% c("basic_statistics", "per_base_sequence_quality", "per_tile_sequence_quality", "per_sequence_quality_scores", "per_base_sequence_content", "per_sequence_gc_content", "per_base_n_content", "sequence_length_distribution", "sequence_duplication_levels", "overrepresented_sequences", "adapter_content")], 
                 column_title = "FastQ QC",
                 column_title_gp = gpar(fontsize = 10),
                 column_names_gp = gpar(fontsize = 8), 
                 row_names_gp = gpar(fontsize = 8),
                 show_row_names = T, 
                 row_names_side = "left",
                 col = c("#F88524","#A1CD64", "#FBE32D"), 
                 cell_fun = function(j, i, x, y, width, height, fill){
                   grid.rect(x = x, y = y, width = width, height = height, 
                             gp = gpar(col = "grey"))}, 
                 name = "QC status") + 
    
    Heatmap(mat[,"X.GC"], 
            column_title = "GC content (%)",
            show_column_names = FALSE, 
            column_title_gp = gpar(fontsize = 10),
            column_title_rot = 90,
            column_names_gp = gpar(fontsize = 8), 
            show_heatmap_legend = FALSE,
            cell_fun = function(j, i, x, y, width, height, fill){
              grid.rect(x = x, y = y, width =2, height = height, 
                        gp = gpar(col = "grey", fill = "white"))
              grid.text(sprintf("%.1f", mat[,"X.GC"][i]), x, y, 
                        gp = gpar(fontsize = 5))
            })+
    
    Heatmap(mat[,"total_deduplicated_percentage"], 
            column_title = "Percentage of reads remaining if deduplicated",
            show_column_names = FALSE, 
            column_title_gp = gpar(fontsize = 10),
            column_title_rot = 90,
            column_names_gp = gpar(fontsize = 8), 
            show_heatmap_legend = FALSE,
            cell_fun = function(j, i, x, y, width, height, fill){
              grid.rect(x = x, y = y, width =2, height = height, 
                        gp = gpar(col = "grey", fill = "white"))
              grid.text(sprintf("%.1f",
                                mat[,"total_deduplicated_percentage"][i]), x, y, 
                        gp = gpar(fontsize = 5))
            })+
    
    Heatmap(mat[,"Sequence.length"], 
            column_title = "Sequence length",
            show_column_names = FALSE, 
            column_title_gp = gpar(fontsize = 10),
            column_title_rot = 90,
            column_names_gp = gpar(fontsize = 8), 
            show_heatmap_legend = FALSE,
            cell_fun = function(j, i, x, y, width, height, fill){
              grid.rect(x = x, y = y, width =2, height = height, 
                        gp = gpar(col = "grey", fill = "white"))
              grid.text(mat[,"Sequence.length"][i], x, y, 
                        gp = gpar(fontsize = 5))
            }) + 
    
    
    Heatmap(mat[,"total_reads"],
            column_title = "total reads (x 10^6)",
            show_column_names = FALSE, 
            column_title_gp = gpar(fontsize = 10),
            column_title_rot = 90,
            show_heatmap_legend = FALSE,
            cluster_columns = F, 
            cluster_rows = F,
            row_names_side = "left", 
            show_row_names = TRUE,
            row_names_gp = gpar(fontsize = 10),
            cell_fun = function(j, i, x, y, width, height, fill){
              grid.text(sprintf("%.1f", mat[,"total_reads"][i]/10^6), 
                        x, y, 
                        gp = gpar(fontsize = 5))}) + 
    
    Heatmap(mat[,"percent_aligned"],
            column_title = "aligned reads (%)",
            show_column_names = FALSE, 
            column_title_gp = gpar(fontsize = 10),
            column_title_rot = 90,
            show_row_names = FALSE, 
            show_heatmap_legend = FALSE,
            cluster_columns = F, 
            cluster_rows = F,
            cell_fun = function(j, i, x, y, width, height, fill){
              grid.text(sprintf("%.1f", mat[,"percent_aligned"][i]), x, y, 
                        gp = gpar(fontsize = 5))}) + 
    
    
    Heatmap(mat[,"pseudoaligned_reads"],
            column_title = "aligned reads (x 10^6)",
            show_column_names = FALSE, 
            column_title_gp = gpar(fontsize = 10),
            column_title_rot = 90,
            show_row_names = FALSE, 
            show_heatmap_legend = FALSE,
            cluster_columns = F, 
            cluster_rows = F,
            cell_fun = function(j, i, x, y, width, height, fill){
              grid.text(sprintf("%.1f",
                                mat[,"pseudoaligned_reads"][i]/10^6), 
                        x, y, 
                        gp = gpar(fontsize = 5))}) + 
    
    rowAnnotation(dist2 = anno_barplot(mat$pseudoaligned_reads, bar_width = 1, gp = gpar(col = NA, fill = "#FFE200"), border = FALSE, which = "row", axis = TRUE), width = unit(1, "cm"))
  
  draw(ht)
}
```

```{r QC Heatmap, cache= T, fig.height= 15}
QCHeatmap()
```


## Exclude samples after QC (based e.g. on number of unique alignments, percent of aligned reads?)
```{r qc sample exclusion}
# define read cutoff
samples_to_keep <- sample_table[sample_table$pseudoaligned_reads > 5000000,]$ID

# make reduced sampleTable file 
sample_table <- sample_table[which(sample_table$ID %in% samples_to_keep),]
rownames(sample_table) <- sample_table$ID
```


## Format sample table 
Define column for test design
Reorder factor levels for later plotting 

```{r colour definitions, eval = F}
## Add columns with factors for comparisons in model
sample_table$Genotype_Age <- factor(sample_table$Genotype_Age, 
                                   levels = c("wt_4mo", "wt_8mo", "wt_12mo", "tg_4mo", "tg_8mo", "tg_12mo"))
sample_table$age <- factor(sample_table$age, levels = c("4mo", "8mo", "12mo"))

# order according to Genotype_Age
sample_table <- sample_table[order(sample_table$Genotype_Age),]

```


We use Tximport and DESeq2 based on the gene-level estimated counts from Kallisto. Additionally, we use the transcript-level abundance estimates to calculate a gene-level offset that corrects for changes to the average transcript length across samples. For more details, please see https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html and http://master.bioconductor.org/packages/release/workflows/vignettes/rnaseqGene/inst/doc/rnaseqGene.html#the-deseqdataset-object-sample-information-and-the-design-formula 

TXimport:
Imports transcript-level abundance, estimated counts and transcript lengths, and summarizes into 
matrices for use with downstream statistical analysis packages such as edgeR, DESeq2, limma-voom. 
Average transcript length, weighted by sample-specific transcript abundance estimates, is provided 
as a matrix which is used as an offset for different expression of gene-level counts.

# DESeq Import and normalization
## Import Kallisto files into R using Tximport
```{r kallisto import}
# Define path where the Kallisto files are stored
files <- paste(dir, "/Data/output/kallisto/kallisto/", samples_to_keep, "/abundance.h5", sep = "")
names(files) <- sample_table$ID

# Import samples and perform the distribution of transcripts to genes
txi_kallisto <- tximport(files, type="kallisto", tx2gene=gene_annotation[,2:1])
```

## DESeq-Dataset and DESeq-function
```{r DESeqDatasetFromTXimport}
dds_txi <- DESeqDataSetFromTximport(txi = txi_kallisto, 
                                    colData = sample_table,
                                    design = ~ condition)
```

## Pre-filtering
Filtering of very low expressed genes that have less than 10 counts summed over all samples
```{r pre-filtering}
genes_to_keep <- rowSums(counts(dds_txi)) >= 10
dds <- dds_txi[genes_to_keep,]
```

Number of genes reliably detected in the data set
```{r}
sum(genes_to_keep) 
```

## Perform DESeq calculations
```{r DESeq calculation}
dds <- DESeq(dds)
```

## Normalized count table
```{r norm}
norm <- as.data.frame(counts(dds, normalized=T))
colnames(norm) <- colnames(dds)
```

## Add gene annotation
```{r gene annotation}
norm_anno <- norm
norm_anno$ENS_ID <- row.names(norm_anno) # ensembl-IDs as row names
norm_anno <- merge(norm_anno, gene_annotation[!duplicated(gene_annotation$GENEID),c("GENEID", "SYMBOL", "GENETYPE")], by.y = "GENEID", by.x = "ENS_ID", all.x = F) 
rownames(norm_anno) <- norm_anno$ENS_ID
```

## Add additional information from biomart
```{r}
biomart <- read.delim(file.path(dir, "Data", "biomart_180914.txt"), stringsAsFactors = FALSE)
idx <- match(unlist(lapply(strsplit(norm_anno$ENS_ID, split = "[.]"), `[[`, 1)), biomart$Gene.stable.ID)
norm_anno$DESCRIPTION <- biomart$Gene.description[idx]
norm_anno$CHR <- biomart$Chromosome.scaffold.name[idx]
```

# Variance stabilizing transformation

In order to test for differential expression, we operate on raw counts and use discrete distributions. However for other downstream analyses - e.g. for visualization or clustering - it might be useful to work with transformed versions of the count data.

Maybe the most obvious choice of transformation is the logarithm. Since count values for a gene can be zero in some conditions (and non-zero in others), some advocate the use of pseudocounts, i.e. transformations of the form: y=log2(n+n0) where n represents the count values and n0 is a positive constant.

DESeq2 has two alternative approaches that offer more theoretical justification and a rational way of choosing parameters equivalent to n0 above. One makes use of the concept of variance stabilizing transformations (VST) (Tibshirani 1988; Huber et al. 2003; Anders and Huber 2010), and the other is the regularized logarithm or rlog, which incorporates a prior on the sample differences (Love, Huber, and Anders 2014). Both transformations produce transformed data on the log2 scale which has been normalized with respect to library size or other normalization factors.

The point of these two transformations, the VST and the rlog, is to remove the dependence of the variance on the mean, particularly the high variance of the logarithm of count data when the mean is low. Both VST and rlog use the experiment-wide trend of variance over mean, in order to transform the data to remove the experiment-wide trend. Note that we do not require or desire that all the genes have exactly the same variance after transformation. Indeed, in a figure below, you will see that after the transformations the genes with the same mean do not have exactly the same standard deviations, but that the experiment-wide trend has flattened. It is those genes with row variance above the trend which will allow us to cluster samples into interesting groups.

The two functions, vst and rlog have an argument blind, for whether the transformation should be blind to the sample information specified by the design formula. When blind equals TRUE (the default), the functions will re-estimate the dispersions using only an intercept. **This setting should be used in order to compare samples in a manner wholly unbiased by the information about experimental groups, for example to perform sample QA (quality assurance) as demonstrated below.**

However, blind dispersion estimation is not the appropriate choice if one expects that many or the majority of genes (rows) will have large differences in counts which are explainable by the experimental design, and one wishes to transform the data for downstream analysis. In this case, using blind dispersion estimation will lead to large estimates of dispersion, as it attributes differences due to experimental design as unwanted noise, and will result in overly shrinking the transformed values towards each other. By setting blind to FALSE, the dispersions already estimated will be used to perform transformations, or if not present, they will be estimated using the current design formula. Note that only the fitted dispersion estimates from mean-dispersion trend line are used in the transformation (the global dependence of dispersion on mean for the entire experiment). So setting blind to FALSE is still for the most part not using the information about which samples were in which experimental group in applying the transformation.

```{r varStab}
dds_vst <- varStab(blind_param = T) 
```

## Plot row standard deviations versus row means
```{r meanSdPlot, echo=TRUE}
meanSdPlot(as.matrix(assay(dds_vst)), ranks = FALSE, 
           ggtitle("Row standard deviations versus row means of variance-stabilized counts"))
```

# Global visualization

## Specify sample annotation for plotting
```{r}
# choose columns from sampletable for heatmap annotation
plot_annotation <- sample_table[,c("condition","age","Mouse_ID","pseudoaligned_reads", "percent_aligned"), drop = F]

rownames(plot_annotation) <- sample_table$ID
plot_annotation$Mouse_ID <- as.factor(plot_annotation$Mouse_ID)
```


## Gene Types
```{r plot genetypes}
TypeCounts <- as.data.frame(table(norm_anno$GENETYPE))
colnames(TypeCounts) <- c("Type", "Frequency")
TypeCounts <- subset(TypeCounts, Frequency>0)

ggplot(TypeCounts, aes(x=Type, y= Frequency,  label=Frequency))+
  geom_bar(stat="identity",fill="lightblue",colour="grey") +
  theme_bw()+
  geom_text(size = 3, position = position_stack(vjust = 1))+
  guides(fill=FALSE)+
  theme(text = element_text(size=10),axis.text.x = element_text(angle =90, hjust = 1))+
  xlab("")

ggsave(file.path(dir, "Analysis", "Plots", paste(Sys.Date(),"_genetypes.pdf", sep = "")))
```

## Hierarchical Clustering of all present genes

### Scaled normalized Counts {.tabset .tabset-fade}
```{r HC normcounts data, echo=TRUE}
heatmap <- t(norm)
row.names(heatmap) <- sample_table$ID
heatmap_scale <- t(scale(heatmap))
heatmap_scale <- heatmap_scale[,rownames(sample_table[order(sample_table$Genotype_Age, decreasing = FALSE),])]
```


#### clustered Columns & Rows
```{r, echo=TRUE, message=FALSE, results='hide', fig.height=10, fig.width=12}
pheatmap(heatmap_scale,
         main="Heatmap of all present genes",
         show_rownames=FALSE,
         show_colnames=TRUE,
         fontsize = 7,
         annotation_col = plot_annotation,
         breaks = scaleColors(maxvalue = 2)[["breaks"]], 
         color = scaleColors(maxvalue = 2)[["color"]])
```

#### clustered Rows
```{r, echo=TRUE, message=FALSE, results='hide', fig.height=10, fig.width=12}
pheatmap(heatmap_scale,
         main="Heatmap of all present genes",
         show_rownames=FALSE,
         show_colnames=TRUE,
         fontsize = 7,
         cluster_cols = F,
         annotation_col = plot_annotation, 
         breaks = scaleColors(heatmap_scale, 2)[["breaks"]], 
         color = scaleColors(heatmap_scale, 2)[["color"]])
```

```{r,echo=FALSE,message=FALSE}
gc()
```

## Hierarchical Clustering of most variable genes

### Scaled normalized Counts {.tabset .tabset-fade}
```{r, echo=TRUE}
rv = rowVars(assay(dds_vst))
q75 = quantile(rowVars(assay(dds_vst)), .75)
q75_vst = assay(dds_vst)[rv > q75,]

heatmap_variablegenes <- t(q75_vst)
row.names(heatmap_variablegenes) <- sample_table$ID
heatmap_variablegenes_scale <- t(scale(heatmap_variablegenes))
heatmap_variablegenes_scale <- heatmap_scale[,rownames(sample_table[order(sample_table$Genotype_Age, decreasing = FALSE),])]
```

####  clustered Columns & Rows
```{r, echo=TRUE, message=FALSE, results='hide', fig.height=10, fig.width=12}
pheatmap(heatmap_variablegenes_scale,
         main="Heatmap of all present genes",
         show_rownames=FALSE,
         show_colnames=TRUE,
         fontsize = 7,
         annotation_col = plot_annotation, 
         breaks = scaleColors(heatmap_variablegenes_scale, 2)[["breaks"]], 
         color = scaleColors(heatmap_variablegenes_scale, 2)[["color"]])
```

####  clustered Rows
```{r, echo=TRUE, message=FALSE, results='hide', fig.height=10, fig.width=12}
pheatmap(heatmap_variablegenes_scale,
         main="Heatmap of all present genes",
         show_rownames=FALSE,
         show_colnames=TRUE,
         fontsize = 7,
         cluster_cols = F,
         annotation_col = plot_annotation, 
         breaks = scaleColors(heatmap_variablegenes_scale, 2)[["breaks"]], 
         color = scaleColors(heatmap_variablegenes_scale, 2)[["color"]])
```

## Sample-to-Sample distances {.tabset .tabset-fade}
### Correlation Plot
```{r, fig.height=10, fig.width=12}
# Correlation based on normalized counts
sampleCor <- cor(assay(dds_vst), use="all.obs", method="pearson")

# Plot Correlation matrix
sampleCor <- as.matrix(sampleCor)
rownames(sampleCor)<- sample_table$ID
colnames(sampleCor)<- sample_table$ID

pheatmap(sampleCor,
         main="Sample Correlation based on normalized counts per sample",
         annotation_row = plot_annotation,
         annotation_col = plot_annotation,
         cluster_rows = F,
         cluster_cols = F,
         fontsize = 6)
```

### Distance Plot
```{r, fig.height=10, fig.width=12}
# Sample Distances based on normalized counts
sampleDists <- dist(t(assay(dds_vst)))

# Plot Distance matrix
sampleDist <- as.matrix(sampleDists)
rownames(sampleDist)<- sample_table$ID
colnames(sampleDist)<- sample_table$ID
pheatmap(sampleDist,
         clustering_distance_rows = sampleDists,
         clustering_distance_cols = sampleDists, 
         main="Sample Distances based on variance-stabilized counts per sample",
         annotation_row = plot_annotation, 
         annotation_col = plot_annotation,
         fontsize = 6)
```

## Principle Component Analysis 
Related to the distance matrix is the PCA plot, which shows the samples in the 2D plane spanned by two principal components. This type of plot is useful for visualizing the overall effect of experimental covariates and batch effects.
To understand the basics of PCA, watch: https://www.youtube.com/watch?v=_UVHneBUBW0

### Percentage of explained variance of PCs
```{r}
pca <- prcomp(t(assay(dds_vst)))
fviz_eig(pca, main= "Eigenvalues")
```
### PCA {.tabset .tabset-fade}
#### Condition
```{r, fig.width=6, fig.height=6, fig}
plot_pca(input=dds_vst,
                        shape_opt="Sex",
                        ntop="all", PC_1=1, PC_2=2,
                        color_obj="Genotype_Age",
                        anno_colour=Genotype_Age_col,
                        continuous=F,
                        colour_gradient=bluered(100),
                        point_size=3,
         title="Principle Component Analysis based on variance-stabilized counts")
```

#### Donor Mouse
```{r, fig.width=6, fig.height=6}
sample_table$Mouse_ID<-as.factor(sample_table$Mouse_ID)
plot_pca(input=dds_vst,
                        shape_opt="NULL",
                        ntop="all", PC_1=1, PC_2=2,
                        color_obj="Mouse_ID",
                        anno_colour=NULL,
                        continuous=F,
                        colour_gradient=bluered(100),
                        point_size=3,
         title="Principle Component Analysis based on variance-stabilized counts")
```

#### Pseudoaligned Reads
```{r, fig.width=6, fig.height=6}
plot_pca(input=dds_vst,
                        shape_opt="NULL",
                        ntop="all", PC_1=1, PC_2=2,
                        color_obj="pseudoaligned_reads",
                        anno_colour=NULL,
                        continuous=T,
                        colour_gradient=bluered(100),
                        point_size=3,
         title="Principle Component Analysis based on variance-stabilized counts")
```

#### Percent of aligned reads
```{r, fig.width=6, fig.height=6}
plot_pca(input=dds_vst,
                        shape_opt="NULL",
                        ntop="all", PC_1=1, PC_2=2,
                        color_obj="percent_aligned",
                        anno_colour=NULL,
                        continuous=T,
                        colour_gradient=bluered(100),
                        point_size=3,
         title="Principle Component Analysis based on variance-stabilized counts")
```




## PCA loadings
```{r}
getLoadings <- function(PC){
  PC_loadings <- pca$rotation[,PC]
  PC_loadings <- PC_loadings[order(PC_loadings, decreasing = T)]
  PC_loadings_20 <-PC_loadings[c(1:20,(length(PC_loadings)-19):length(PC_loadings))]
  names(PC_loadings_20)
}

PC1_loadings <- getLoadings("PC1")
PC2_loadings <- getLoadings("PC2")
PC3_loadings <- getLoadings("PC3")

plotLoadings <- function(Loadings, PC){
  heatmap <- norm_anno[rownames(norm_anno) %in% Loadings,]
  rownames(heatmap) <- heatmap$SYMBOL
  heatmap <- heatmap[,colnames(heatmap) %in% sample_table$ID]
  heatmap_scale <- as.matrix(t(scale(t(heatmap))))
  heatmap_scale <- heatmap_scale[,rownames(sample_table[order(sample_table$Genotype_Age, decreasing = FALSE),])]
  
  # Heatmap
  pheatmap(heatmap_scale,
           main=paste("Hierarchical Clustering of top20 ",PC, " loadings in both directions",sep=""),
           show_rownames=TRUE,
           show_colnames = TRUE,
           annotation_col = plot_annotation,
           cluster_cols = F,
           fontsize=5)
}
plotLoadings(Loadings = PC1_loadings,PC="PC1")
plotLoadings(Loadings = PC2_loadings,PC="PC2")
plotLoadings(Loadings = PC3_loadings,PC="PC3")
```

# Gene-to-Gene Correlation Analysis over all samples
```{r}
rv = rowVars(assay(dds_vst))
q75 = quantile(rowVars(assay(dds_vst)), .75)
q75_vst = assay(dds_vst)[rv > q75,]

rcor <- rcorr(t(q75_vst),type="pearson")
rcor$sig <- rcor$P<0.05 & rcor$r>0 # define significant positive correlations
rcor_filt <- rcor$r*rcor$si
rcor_filt <- rcor_filt*upper.tri(rcor_filt)
rcor_filt<- replace(rcor_filt, which( rcor_filt==0), NA)
rcor_filt_melt <- melt(rcor_filt,na.rm = TRUE)

rcor_filt_melt_cutoff <- rcor_filt_melt[rcor_filt_melt$value>0.95,]
head(rcor_filt_melt_cutoff)

# calculate and plot scaled normalized values
tmp <- as.data.frame(t(norm))
scaled_norm <- t(scale(t(norm)))
scaled_norm <- scaled_norm[,rownames(sample_table[order(sample_table$Genotype_Age, decreasing = FALSE),])]
input <- scaled_norm[rownames(scaled_norm)%in% rcor_filt_melt_cutoff$Var1,]

pheatmap(input,
        main="Hierarchical Clustering of the scaled normalized values",
        show_rownames=FALSE,
        show_colnames = TRUE,
        cluster_cols = FALSE,
        annotation_col = plot_annotation,
        fontsize=8,
        breaks = scaleColors(input, 2)[["breaks"]],
        color = scaleColors(input, 2)[["color"]])
```

# Check for batch effect within the data

If your anaylsis above showed you that your data does not cluster in the conditions you want to compare or if you notice that your samples cluster according to a certain covariate you may call this covariate which you are not interested in (e.g. different sequencing day) a batch effect. For known batch effects such as sequencing day or gender you may try to disregard the variance explained by this covariate in your later differential gene expression analysis. To check whether disregarding the variance explained by this covariate really improves the clustering of your samples you can correct your gene expression for this factor using limma. (https://bioconductor.org/packages/release/bioc/html/limma.html)

```{r}
Limma_batch(model=model.matrix(~sample_table$condition),
            batch=sample_table[c("age")],
            batch_2=NULL,
            shape_opt="NULL",
            ntop=500, PC_1=1, PC_2=2,
            color_obj=sample_table$Genotype_Age,
            anno_colour=Genotype_Age_col,
            continuous=F,
            colour_gradient=redblue(100),
            point_size=3)
```

In case your samples do not cluster according to the condition you are interested in, you may also try to find a hidden batch effect. The SVA tool finds all the variance in the data that is not explained by your covariates of interest and tries to model them out by adding surrogate variables to your sample_table that may even out these "hidden batches" in the later DESeq2 modeling. (http://master.bioconductor.org/packages/release/workflows/html/rnaseqGene.html#removing-hidden-batch-effects; http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0030161)
We first calculate these surrogate variables (SV) and then test their influence on our data in a PCA by using limma again to model the disregarding of the hidden batches.

By num.sv you can calculate how many SV the tool recommends you to use. However, you will have to test out different amounts of SV as this calculation is very vague and usually does not make much sense.
```{r}
# Enter your variable to compare (your biological question) 
# behind the ~ & SVA defines a matrix for your conditions
mod  <- model.matrix(~ condition, sample_table)
mod0 <- model.matrix(~   1, colData(dds))

# By num.sv you can calculate how many SV the tool recommends you to use. However, you will have to test out different amounts of SV as this calculation is very vague and usually does not make much sense.
num.sv(norm,mod,method="leek")
```

You can then either try out the recommended amount of SV by changing n.sv or you start from n.sv=1 and go up and stop where your PcA starts to cluster more nicely as you expect it.
```{r}
# By changing n.sv you can choose how many SV to calculate.
svseq<- sva(assay(dds_vst), mod, mod0, n.sv = 7)
```

You can display whether the calculated SV correlate with any of your known covariates by changing dds$condition to the column of your sample_table that you are interested in.
```{r}
par(mfrow = c(2, 2), mar = c(3,5,3,1))
for (i in 1:ncol(svseq$sv)) {
  stripchart(svseq$sv[, i] ~ dds$condition, vertical = TRUE, main = paste0("SV", i))
  abline(h = 0)
}
```

Add surrogate variables to annotation table to reanalyse the batch effect via Limma.
```{r}
for (i in 1:ncol(svseq$sv)) {
  sample_table[[paste0("SV",i)]]<- svseq$sv[, i]
}
```



Here, we check on a PCA what influence the SVA has on the clustering of the samples.
```{r}
Limma_batch(model=model.matrix(~sample_table$condition),
            batch=sample_table[grep("SV",colnames(sample_table))],
            batch_2=NULL,
            shape_opt="NULL",
            ntop=500, PC_1=1, PC_2=2,
            color_obj=sample_table$Genotype_Age,
            anno_colour=Genotype_Age_col,
            continuous=F,
            colour_gradient=redblue(100),
            point_size=3)
```

##### SVA into design formula ####

To exclude the variance explained by the batch in your later analysis, you may enter the calculated SVs to the sample_table within the DESeq2 object as well.
```{r}
for (i in 1:ncol(svseq$sv)) {
  dds[[paste0("SV",i)]]<- svseq$sv[, i]
}
```

In case you want to include the found batch variable (no matter if SV or a known covariate from you sample_table) you can include these in your design formlua in front of the condition of interest and recalculate your dds object.
In the following expample we will not include a batch effect. 
```{r}
#design(dds) <- ~ SV1 + SV2 + SV3 + SV4 + SV5 + SV6 + SV7 + merged
#design <- design(dds)

#dds %<>% DESeq
```
In this step we may also generate a batch-corrected table of the normalized expression of all genes derived from running Limma on the rlog transformed data.

To generate the batch-corrected expression table you need to set the columns from sample_table that explain the batch in "batch". For numeric batches (e.g. SVA) you can set multiple columns in the "batch" (e.g.: sample_table[c("total_reads","pseudoaligned_reads","not_pseudoaligned_reads","percent_aligned")]). For factors you can set maximally 2 columns (one in "batch": sample_table[c("age")] and one in "batch_2": sample_table$Genotype_Age). If you have no second "batch_2" parameter, just leave it as NULL.
```{r}
dds_vst_f <- varStab(blind_param = F)
dds_vst_f_df <- as.data.frame(assay(dds_vst_f))
dds_batch_corrected_log2 <- removeBatchEffect_function(x=dds_vst_f_df,batch =sample_table[c("age")],batch_2=NULL,model =model.matrix(~sample_table$condition))
# transform log2 values to non-log transformed counts
dds_batch_corrected <-dds_batch_corrected_log2
dds_batch_corrected[1:ncol(dds_batch_corrected)]<- lapply(dds_batch_corrected,logratio2foldchange)
# add the gene annotations to the table
dds_batch_corrected$ENS_ID <- row.names(dds_batch_corrected) # ensembl-IDs as row names
dds_batch_corrected <- merge(dds_batch_corrected, gene_annotation[!duplicated(gene_annotation$GENEID),c("GENEID", "SYMBOL", "GENETYPE")], by.y = "GENEID", by.x = "ENS_ID", all.x = F) 
rownames(dds_batch_corrected) <- dds_batch_corrected$ENS_ID
```
# Differential Expression Analysis

### Defining your comparisons
Define your comparisons in a data.frame with "comparison" in the first column & "control" in the second column.
```{r}
comparison<-c("tg_8mo","tg_4mo","tg_12mo")
control<-c("wt_8mo","wt_4mo","wt_12mo")
comparison_table<-data.frame(comparison,control)
design(dds)<-~ Genotype_Age
dds %<>% DESeq
```

This table will be used to create an entry in an object named "DE_object" where the results of the DESeq2 analysis are saved to gether with a list of the DE genes and the amount of DE genes found.By default IHW will be used as a multiple testing method (https://bioconductor.org/packages/3.7/bioc/vignettes/IHW/inst/doc/introduction_to_ihw.html). 
You can also edit the multiple testing method by setting the multiple_testing parameter to "holm", "hochberg", "hommel", "bonferroni", "BH", "BY",or "fdr". "BH" (Bonferroni-Hochberg) is the most common multiple testing method. The multiple testing can be turned of by setting it to "none". 
The threshold of the adjusted p value for significance can be changed in "alpha_option", lfc_Threshold decides on the biological threshold for genes to be defined as differentially expressed (0.58 equals a fold-change of 1.5, 0.266 equals a fold-change of 1.2).

### Creating your DE_object containing all the demanded comparisons
```{r}
DE_object <- DEAnalysis(alpha_option=0.05, 
                          lfc_Threshold=0.58, 
                          condition = "Genotype_Age",
                          multiple_testing="IHW")
#Guiding through the DE_object
#look at parameters used
#DE_object$tg_VS_wt@parameters #IHW(T or F),significance threshold, lfc threshold, comparison, control
#results table
#head(DE_object$tg_VS_wt@results,6)
#DE gene lists (up & down)
#head(DE_object$tg_VS_wt@DE_genes$`up-regulated genes`,6)
#head(DE_object$tg_VS_wt@DE_genes$`down-regulated genes`,6)
##Look at the amount of DE genes found
#DE_object$tg_VS_wt@Number_DE_genes$`up-regulated genes`
#DE_object$tg_VS_wt@Number_DE_genes$`down-regulated genes`
```

### Visualization of DE results

```{r}

```


# Plotting the expression of a single gene across conditions

There needs to be some changes due to the two added columns "DESCRIPTION" & "CHR" in norm_anno!

Single genes can be observes. It is still of debate whether to use the normalized counts for this function or to use the batch-corrected counts as input. 
```{r}
# You can either enter norm_anno to plot the normalized counts or dds_batch_corrected to plot the batch-corrected counts
plot_single_gene(input=norm_anno, gene_symbol="Crybg3", 
                                       condition="Genotype_Age", anno_colour=Genotype_Age_col,
                                       shape_opt="age")
norm_anno[which(duplicated(norm_anno$SYMBOL)),]$SYMBOL
```


# Export

## Count table as txt
Exporting the annotated, normalized expression table:
```{r}
write.table(norm_anno, 
            paste(dir, "/Analysis/", "Tables/", "DESeq2norm_anno_filt_", Sys.Date(), ".txt", sep = ""), 
            sep = "\t", 
            quote = F, 
            row.names = F)
```

## Count table, normalized table and stats as Excel sheet
As an optimal output for cooperation partners we create an Excel sheet with the normalized table, the batch corrected table & the statistics of comparisons. The DE genes can be subsetted in the sheets by filtering for significance=T.
Either the output can be an excel sheet with a tab for every comparison....
```{r , echo=TRUE, message=FALSE}
DESeq2_object<-createWorkbook(type="xlsx")
sheet <- createSheet(DESeq2_object, sheetName = "Sample_table")
addDataFrame(sample_table, sheet, startRow=1, startColumn=1)
sheet <- createSheet(DESeq2_object, sheetName = "Annotated gene counts")
addDataFrame(norm_anno, sheet, startRow=1, startColumn=1)
sheet <- createSheet(DESeq2_object, sheetName = "Batch_corrected gene expression")
addDataFrame(dds_batch_corrected, sheet, startRow=1, startColumn=1)
for (i in 1:length(names(DE_object))) {
  sheet <- createSheet(DESeq2_object, sheetName = paste(names(DE_object)[[i]]))
  addDataFrame(DE_object[[i]]@results, sheet, startRow=1, startColumn=1)}
saveWorkbook(DESeq2_object, file=file.path(dir, "Analysis", "Tables", "DESeq2_object.xlsx"))
```

or with all comparisons in one tab. 
```{r}
DESeq2_object<-createWorkbook(type="xlsx")
sheet <- createSheet(DESeq2_object, sheetName = "Sample_table")
addDataFrame(sample_table, sheet, startRow=1, startColumn=1)
sheet <- createSheet(DESeq2_object, sheetName = "Annotated gene counts")
addDataFrame(norm_anno, sheet, startRow=1, startColumn=1)
sheet <- createSheet(DESeq2_object, sheetName = "Batch_corrected gene expression")
addDataFrame(dds_batch_corrected, sheet, startRow=1, startColumn=1)
Results<-data.frame(DE_object[[1]]@results)
for (i in 2:length(names(DE_object))) {
  Results<-cbind(Results,DE_object[[i]]@results)}
sheet <- createSheet(DESeq2_object, sheetName = "Results")
addDataFrame(Results, sheet, startRow=1, startColumn=1)
saveWorkbook(DESeq2_object, file=file.path(dir, "Analysis", "Tables", "DESeq2_object_combined.xlsx"))
```

## Image and session Info
```{r}
save.image(paste(dir, "/Analysis/", Sys.Date(), "_Image.RData", sep = ""))
sessionInfo()
```